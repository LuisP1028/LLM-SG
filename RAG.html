<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Part III: RAG Architectures // Study Guide</title>
<style>
    :root {
        --bg-color: #000000;
        --text-color: #00ff41;
        --accent-color: #00ff41;
        --dim-color: #003b00;
        --border-color: #00ff41;
        --font-main: 'Courier New', Courier, monospace;
        --font-header: 'Arial Black', Impact, sans-serif;
    }

    * { box-sizing: border-box; }

    body {
        margin: 0;
        padding: 0;
        background-color: var(--bg-color);
        color: var(--text-color);
        font-family: var(--font-main);
        line-height: 1.5;
        overflow-x: hidden;
    }

    /* --- VISUALS --- */
    .dither-layer {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        z-index: -1;
        background-image: radial-gradient(circle, #003b00 1px, transparent 1px);
        background-size: 4px 4px;
        opacity: 0.4;
    }

    .scanlines {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        background: linear-gradient(to bottom, rgba(0, 255, 65, 0), rgba(0, 255, 65, 0) 50%, rgba(0, 20, 0, 0.2) 50%, rgba(0, 20, 0, 0.2));
        background-size: 100% 4px;
        pointer-events: none;
        z-index: 9999;
    }

    .container {
        max-width: 900px;
        width: 100%;
        margin: 0 auto;
        padding: 40px 20px;
        border-left: 2px dashed var(--dim-color);
        border-right: 2px dashed var(--dim-color);
        background-color: rgba(0, 10, 0, 0.9);
        min-height: 100vh;
    }

    /* --- TYPOGRAPHY --- */
    h1 {
        font-family: var(--font-header);
        text-transform: uppercase;
        font-size: 2.5rem;
        border-bottom: 5px solid var(--accent-color);
        margin-bottom: 40px;
        color: var(--accent-color);
        text-align: center;
        text-shadow: 0px 0px 8px var(--accent-color);
        word-wrap: break-word;
    }

    h3 { margin-top: 0; color: var(--accent-color); text-transform: uppercase; }
    strong { color: var(--accent-color); text-decoration: underline; }
    em { font-style: normal; color: #50c878; border-bottom: 1px dotted var(--dim-color); }

    /* --- ACCORDION STYLES --- */
    /* Outer Parts */
    details.part {
        margin-bottom: 30px;
        border: 2px solid var(--border-color);
        background: #000;
        box-shadow: 6px 6px 0px var(--dim-color);
        transition: transform 0.1s;
    }
    details.part[open] { box-shadow: 4px 4px 0px var(--dim-color); transform: translate(2px, 2px); }
    details.part > summary {
        font-family: var(--font-header);
        font-size: 1.5rem;
        padding: 15px 20px;
        background-color: var(--accent-color);
        color: var(--bg-color);
        cursor: pointer;
        list-style: none;
        text-transform: uppercase;
        position: relative;
    }
    details.part > summary::-webkit-details-marker { display: none; }
    details.part > summary::after { content: '+'; position: absolute; right: 20px; font-weight: 900; }
    details.part[open] > summary::after { content: '-'; }
    .part-content { padding: 20px; border-top: 2px solid var(--border-color); }

    /* Inner Sections */
    details.section {
        margin-bottom: 15px;
        border: 1px solid var(--dim-color);
        background: #050505;
    }
    details.section > summary {
        font-family: var(--font-main);
        font-weight: bold;
        padding: 12px;
        background: #0a0a0a;
        color: var(--text-color);
        cursor: pointer;
        list-style: none;
        border-bottom: 1px solid transparent;
        text-transform: uppercase;
        font-size: 1.1rem;
    }
    details.section > summary:hover { background: var(--dim-color); color: var(--accent-color); }
    details.section[open] > summary {
        border-bottom: 1px solid var(--dim-color);
        background: #0f0f0f;
        color: var(--accent-color);
        text-shadow: 0px 0px 5px var(--accent-color);
    }
    .section-content { padding: 20px; }

    /* Subsections */
    .subsection {
        margin-bottom: 25px;
        border-left: 4px solid var(--dim-color);
        padding-left: 15px;
    }
    .subsection-title {
        background: var(--dim-color);
        color: var(--accent-color);
        padding: 2px 6px;
        font-weight: bold;
        text-transform: uppercase;
        display: inline-block;
        margin-bottom: 10px;
        font-size: 0.9rem;
    }

    p { margin-bottom: 12px; margin-top: 0; text-align: justify; }
    ul { padding-left: 20px; margin-bottom: 15px; }
    li { margin-bottom: 5px; }

    .code-block {
        background: #020a02;
        border: 1px dashed var(--dim-color);
        padding: 10px;
        margin: 10px 0;
        font-family: 'Courier New', monospace;
        color: var(--accent-color);
        overflow-x: auto;
        white-space: pre-wrap;
    }

    /* --- INTERACTIVE: EYE BUTTON & VIEWPORT --- */
    
    .eye-btn {
        position: relative;
        width: 28px; height: 28px;
        background: #000;
        border: 1px solid var(--accent-color);
        cursor: pointer;
        padding: 4px;
        display: inline-flex;
        align-items: center; justify-content: center;
        margin-left: 8px;
        vertical-align: bottom;
        transition: transform 0.1s;
    }
    .eye-btn svg { width: 100%; height: 100%; fill: var(--accent-color); }
    .eye-btn:hover {
        background: var(--accent-color);
        transform: translate(-1px, -1px);
        box-shadow: 2px 2px 0px var(--dim-color);
    }
    .eye-btn:hover svg { fill: #000; }

    .dither-bg {
        background-image: 
            linear-gradient(45deg, var(--dim-color) 25%, transparent 25%), 
            linear-gradient(-45deg, var(--dim-color) 25%, transparent 25%), 
            linear-gradient(45deg, transparent 75%, var(--dim-color) 75%), 
            linear-gradient(-45deg, transparent 75%, var(--dim-color) 75%);
        background-size: 4px 4px;
    }

    .retro-viewport {
        position: fixed;
        top: 50%; left: 50%;
        transform: translate(-50%, -50%);
        width: 80vw; height: 80vh;
        max-width: 900px; max-height: 700px;
        background-color: #000;
        border: 2px solid var(--accent-color);
        box-shadow: 0 0 50px rgba(0, 50, 0, 0.8);
        display: flex; flex-direction: column;
        z-index: 10000;
        visibility: hidden; opacity: 0;
        pointer-events: none;
        transition: opacity 0.2s;
        resize: both; overflow: hidden;
    }
    .retro-viewport.active { visibility: visible; opacity: 1; pointer-events: auto; }

    .vp-header {
        background: var(--accent-color);
        color: #000;
        padding: 5px 10px;
        font-weight: bold;
        font-family: var(--font-header);
        display: flex; justify-content: space-between;
        align-items: center;
        border-bottom: 2px solid #000;
        cursor: default;
    }
    .vp-close {
        background: #000; color: var(--accent-color);
        border: 1px solid #000; font-weight: 900; 
        cursor: pointer; font-family: var(--font-main);
    }
    .vp-close:hover { background: #fff; color: #000; }
    
    .vp-body { flex-grow: 1; position: relative; background: #000; }
    .vp-body iframe { width: 100%; height: 100%; border: none; }

    /* --- RESPONSIVE --- */
    @media (max-width: 600px) {
        h1 { font-size: 1.8rem; border-bottom-width: 3px; }
        details.part > summary { font-size: 1.1rem; padding: 12px; }
        details.section > summary { font-size: 0.9rem; }
        .container { padding: 10px; border: none; }
        .part-content, .section-content { padding: 10px; }
        p { text-align: left; }
        .retro-viewport { width: 95vw; height: 60vh; }
    }
</style>
</head>
<body>
<div class="dither-layer"></div>
<div class="scanlines"></div>
<div class="container">
<h1>Part III: RAG Architectures</h1>

<div class="part-content">
        
        <details class="section">
            <summary>1. RAG Overview & Modules</summary>
            <div class="section-content">
                <p><strong>RAG:</strong> Pulling new, updated, tailored information from a vector store to concatenate as context to a user prompt, before feeding a foundational model.</p>
                <p><strong>A RAG system is composed of three main modules:</strong></p>
                <ul>
                    <li>Ingestion pipeline: A batch or streaming pipeline used to populate the vector DB</li>
                    <li>Retrieval pipeline: A module that queries the vector DB and retrieves relevant entries to the user’s input</li>
                    <li>Generation pipeline: The layer that uses the retrieved data to augment the prompt and an LLM to generate answers</li>
                </ul>
                
                <div class="subsection">
                    <span class="subsection-title">HOW ARE MODULES CONNECTED OVERVIEW</span>
                    <ol>
                        <li>On the backend side, the ingestion pipeline runs either on a schedule or constantly to populate the vector DB with external data.</li>
                        <li>On the client side, the user asks a question.</li>
                        <li>The question is passed to the retrieval module, which preprocesses the user’s input and queries the vector DB.</li>
                        <li>The generation pipelines use a prompt template, user input, and retrieved context to create the prompt.</li>
                        <li>The prompt is passed to an LLM to generate the answer.</li>
                        <li>The answer is shown to the user.</li>
                    </ol>
                </div>
            </div>
        </details>

        <details class="section">
            <summary>2. RAG: Chunking</summary>
            <div class="section-content">
                <p>Chunking is the process of splitting large documents into smaller, discrete segments. In RAG systems, it is essential for:</p>
                <ul>
                    <li><strong>Context Limits:</strong> Ensures text fits within an LLM’s token constraints.</li>
                    <li><strong>Retrieval Precision:</strong> Improves semantic search by focusing on specific topics rather than broad documents.</li>
                    <li><strong>Relevancy:</strong> Helps the model generate accurate answers by providing only the most pertinent context.</li>
                </ul>
                <hr>
                <ul>
                    <li>
                        <strong>Fixed-size Chunking:</strong> Slices text into hard segments based on a strict token or character limit (e.g., 512 tokens). While computationally efficient, it ignores semantic structure, often breaking sentences mid-thought. To mitigate context loss at the edges, a "sliding window" overlap (10-20%) is applied.
                        <ul>
                            <li><em>Example:</em> Processing a raw server log file. You blindly cut the text every 500 characters, regardless of where the line ends.</li>
                            <li><em>When to use:</em> Ideal for uniform data streams or simple tasks where computational speed is the priority and semantic context is less critical (e.g., n-gram analysis).</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Recursive Chunking:</strong> Iteratively breaks down text using a hierarchy of separators to fit specific size limits. It attempts to split by largest structural elements first (like paragraphs), then sentences, then words.
                        <ul>
                            <li><em>Example:</em> An article is split first by double newlines (paragraphs). If a paragraph is still too big, it splits by periods (sentences).</li>
                            <li><em>When to use:</em> The "default" best choice for general prose, articles, and essays. It respects natural reading flow, keeping related ideas (paragraphs) intact.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Content-aware / Syntactic Chunking:</strong> Leverages the distinct formatting logic of the source file to define boundaries. For code, it splits by functions or classes; for Markdown or HTML, it splits by headers or tags.
                        <ul>
                            <li><em>Example:</em> Splitting a Python script by <code>def</code> blocks or an HTML file by <code>&lt;div&gt;</code> tags, ensuring no function is cut in half.</li>
                            <li><em>When to use:</em> Essential for structured documents like Code, Markdown, or JSON. It prevents breaking syntax, ensuring the retrieved chunk is valid and executable.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Semantic Chunking:</strong> Semantic chunking splits text into sentences and converts them to embeddings to assess similarity (usually via cosine). Chunks grow as long as sentences stay semantically close; once distance exceeds a threshold, a new chunk starts. This linear process preserves document order and context for accurate retrieval.
                        <ul>
                            <li><em>Example:</em> A transcript moves from discussing "Weather" to "Stocks." The system detects the topic shift via embeddings and cuts the chunk exactly there.</li>
                            <li><em>When to use:</em> Best for RAG systems requiring high precision. It ensures a chunk contains only one distinct concept, reducing noise for the LLM.</li>
                        </ul>
                    </li>
                </ul>
            </div>
        </details>


        <details class="section">
            <summary>3. RAG Ingestion: Walkthrough</summary>
            <div class="section-content">
                <ol>
                    <li><strong>Pull in the raw data (Data extraction/Ingestion):</strong> Collect documents from databases, PDFs, APIs, etc.</li>
                    <li><strong>Clean it up (Cleaning layer):</strong> Fix messy text: remove weird characters, strip URLs, delete headers/footers.</li>
                    <li><strong>Break into smaller pieces (Chunking/Splitting):</strong> Split large documents into 300-800 word chunks. Smart chunking keeps complete thoughts together.</li>
                    <li><strong>Turn into vectors (Embedding):</strong> Send chunks to an embedding model. Text becomes numerical vectors capturing meaning.</li>
                    <li><strong>Save in vector database (Loading):</strong> Store vectors + metadata (source URL, date, title) in a vector DB.</li>
                </ol>
                <p><strong>Result:</strong> When users ask questions, the system searches vectors for relevant chunks, adds them to the prompt, and the LLM generates accurate, grounded answers.</p>
                <p><strong>In short:</strong> Raw documents &rarr; cleaned &rarr; chunked &rarr; vectorized &rarr; stored &rarr; ready for AI retrieval.</p>
            </div>
        </details>

        <details class="section">
            <summary>4. Indexing Methods in a Vector Database</summary>
            <div class="section-content">
                <p><strong>What is a Vector DB:</strong> Traditional databases look for exact word matches, but vector DBs find data that is <em>similar</em> to your query. They organize information as numeric vectors using specialized indexes.</p>
                
                <div class="subsection">
                    <span class="subsection-title">HNSW (Hierarchical Navigable Small World)</span>
                    <button class="eye-btn" onclick="let vp = document.querySelector('.retro-viewport'); vp.querySelector('iframe').src='RAG/HNSW.html'; vp.classList.add('active');">
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                            <path d="M12 4.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5zM12 17c-2.76 0-5-2.24-5-5s2.24-5 5-5 5 2.24 5 5-2.24 5-5 5zm0-8c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/>
                        </svg>
                    </button>
                    <p>Constructs a multi-layered graph structure. Upper layers contain sparse nodes for rapid "greedy" traversal. Lower layers are denser for fine-grained navigation. Ensures logarithmic search complexity trading high memory usage for speed.</p>
                </div>
        
                <div class="subsection">
                    <span class="subsection-title">LSH (Locality-Sensitive Hashing)</span>
                    <button class="eye-btn" onclick="let vp = document.querySelector('.retro-viewport'); vp.querySelector('iframe').src='RAG/LSH.html'; vp.classList.add('active');">
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                            <path d="M12 4.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5zM12 17c-2.76 0-5-2.24-5-5s2.24-5 5-5 5 2.24 5 5-2.24 5-5 5zm0-8c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/>
                        </svg>
                    </button>
                    <p>Projects vectors onto random hyperplanes to generate binary signatures. Vectors on the same side land in the same "bucket". Querying becomes an O(1) lookup.</p>
                </div>
        
                <div class="subsection">
                    <span class="subsection-title">Product Quantization (PQ)</span>
                    <button class="eye-btn" onclick="let vp = document.querySelector('.retro-viewport'); vp.querySelector('iframe').src='RAG/PQ.html'; vp.classList.add('active');">
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                            <path d="M12 4.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5zM12 17c-2.76 0-5-2.24-5-5s2.24-5 5-5 5 2.24 5 5-2.24 5-5 5zm0-8c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/>
                        </svg>
                    </button>
                    <ul>
                        <li>Quantization approximates precise values using limited "centroids."</li>
                        <li>PQ is vital when datasets exceed RAM limits. It acts as a rapid <strong>pre-filter</strong>.</li>
                        <li>Breaks vectors into sub-parts, quantizing each to create a compact code. The <strong>Signature Matrix</strong> stores these compressed IDs.</li>
                    </ul>
                </div>
        
                <div class="subsection">
                    <span class="subsection-title">Random Projection (RP)</span>
                    <button class="eye-btn" onclick="let vp = document.querySelector('.retro-viewport'); vp.querySelector('iframe').src='RAG/random_projection.html'; vp.classList.add('active');">
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                            <path d="M12 4.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5zM12 17c-2.76 0-5-2.24-5-5s2.24-5 5-5 5 2.24 5 5-2.24 5-5 5zm0-8c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/>
                        </svg>
                    </button>
                    <p>Reduces dimensionality by multiplying vectors with a fixed random matrix. Maps data to lower-dimensional space while preserving relative distances.</p>
                </div>
            </div>
        </details>
        </details>



                <div class="subsection">
                    <span class="subsection-title">2. Retrieval</span>
                    <p>Improves vector search by upgrading embedding models and applying metadata filtering.</p>
                    <p><strong>Fine-tuning Embedding Models:</strong> Tailors pre-trained models to domain jargon.</p>
                    <div class="code-block">EMBEDDING FINE TUNING SIMPLIFIED:
Vectorization: The model maps the Query and Candidates to coordinates.
Scoring: Computes similarity scores (dot product).
Alignment: Loss maximizes Query-Positive score.
Differentiation: Loss penalizes Query placement near Negatives.
Update: Tweak weights so Query lands closer to Positive.</div>
<p><strong>Instructor Models:</strong> Guides embedding generation using specific prompts.</p>
<p><strong>Hybrid Search:</strong> Blends vector search with keyword-based search.</p>
<p><strong>Filtered Vector Search:</strong> Leverages metadata indexes to narrow search space.</p>
</div>

<div class="subsection">
                  <span class="subsection-title">3. Post-retrieval</span>
                  <p>Filters noise from results and compresses context (Reranking).</p>
              </div>
          </div>
      </details>

      <details class="section">
          <summary>6. RAG Evaluation</summary>
          <div class="section-content">
              <p>Standard LLM tests check internal knowledge. <strong>RAG evaluation</strong> assesses the whole system: Retrieval and Generation.</p>
              
              <div class="subsection">
                  <span class="subsection-title">RAGAS Framework</span>
                  <p>Uses <strong>LLM-as-a-judge</strong> to evaluate the relationship between Question, Context, and Answer.</p>
                  
                  <p><strong>1. Faithfulness:</strong> Measures hallucination. Does the answer come <em>only</em> from the context? Calculated by verifying atomic statements against context.</p>
                  <p><strong>2. Answer Relevancy:</strong> Does the response address the user's query? Uses "Reverse Engineering"—generating questions from the answer and comparing vector similarity to the original question.</p>
                  <p><strong>3. Context Precision:</strong> Are relevant chunks ranked at the top?</p>
              </div>

              <div class="subsection">
                  <span class="subsection-title">How It Works</span>
                  <p><strong>Data Preparation:</strong> Need Question, Contexts, Answer, Ground Truth.</p>
                  <p><strong>Evaluation Loop:</strong> Evaluator LLM performs Extraction (claims), Verification (logic check), and Back-Projection (relevance check).</p>
              </div>
          </div>
      </details>

      <details class="section">
          <summary>7. RAG: Embedding</summary>
          <div class="section-content">
              <p><strong>Dense Embeddings:</strong> Foundation for semantic search. Captures abstract meaning (e.g., "dog" matches "canine").</p>
              <p><strong>Sparse Embeddings:</strong> Foundation for lexical search. High-dimensional vectors mapping to specific tokens. Essential for exact keyword matching.</p>
              <p><strong>Contextualized Token Embeddings:</strong> Foundation for fine-grained matching (e.g., BERT, ColBERT). Generates separate vectors for each token.</p>
              <p><strong>Contrastive Learning Embeddings:</strong> Foundation for similarity learning. Pulls similar examples together, pushes dissimilar apart.</p>
          </div>
      </details>

      <details class="section">
          <summary>9. End to End Optimized RAG Inference Flow</summary>
          <div class="section-content">
              <div class="subsection">
                  <span class="subsection-title">1. The Core RAG Synthesis</span>
                  <ul>
                      <li><strong>Retrieval & Context Mapping:</strong> ContextRetriever fetches and maps chunks.</li>
                      <li><strong>The Prompt Factory:</strong> Constructs "Augmented Prompt" with template.</li>
                      <li><strong>Inference Execution:</strong> Sends to LLM for grounded answer.</li>
                  </ul>
              </div>
              <div class="subsection">
                  <span class="subsection-title">2. Optimization: Conversation Memory</span>
                  <p>Uses Sliding Window or Summarization Strategy to handle stateless LLMs.</p>
              </div>
              <div class="subsection">
                  <span class="subsection-title">3. Optimization: Intelligent Routing</span>
                  <p>Semantic Router directs searches to specific repositories (e.g., Code vs Articles) to save cost.</p>
              </div>
              <div class="subsection">
                  <span class="subsection-title">4. Optimization: Hybrid Search</span>
                  <p>Combines Vector Search and BM25 using score normalization and weighted merging.</p>
              </div>
              <div class="subsection">
                  <span class="subsection-title">5. Optimization: Multi-Index Vectors</span>
                  <p>Embeds metadata (Platform, Date) into the vector index to weigh authority/recency.</p>
              </div>
          </div>
      </details>

      <details class="section">
        <summary>10. Advanced Retrieval Strategies: Self-Querying, Expansion & Reranking</summary>
        <div class="section-content">
            
            <div class="subsection">
                <span class="subsection-title">A. Self-Querying / Filtered Vector Search</span>
                <p><em>Best for finding "x" with strict constraints "y" (Focus: Precision & Security).</em></p>
                <p><strong>Process:</strong></p>
                <ol>
                    <li><strong>Scope and Configuration:</strong> Loads Metadata Schema.</li>
                    <li><strong>Schema-Based Extraction:</strong> Maps text to structured categories (e.g., author: Paul).</li>
                    <li><strong>Entity Resolution:</strong> Resolves names to UUIDs.</li>
                    <li><strong>Query Enrichment:</strong> Combines semantic text with hard identifiers.</li>
                    <li><strong>Filtered Retrieval:</strong> DB executes search with strict metadata gates.</li>
                </ol>
                <p><strong>Technical Breakdown:</strong></p>
                <ul>
                    <li><strong>Metadata Schema Definition:</strong> Tag vectors during ingestion.</li>
                    <li><strong>Self-Query Phase:</strong> LLM extracts filters (e.g., Year: 2024).</li>
                    <li><strong>Pre-Filtering Execution:</strong> Masks non-matching documents <em>before</em> similarity calculation.</li>
                    <li><strong>Vector Similarity Search:</strong> Calculates distance only on surviving candidates.</li>
                </ul>
            </div>
    
            <hr style="border-top: 1px dashed #ccc; margin: 15px 0;">
    
            <div class="subsection">
                <span class="subsection-title">B. Query Expansion & Reranking</span>
                <p><em>Best for finding "x" and synonyms (Focus: Recall).</em></p>
                <p><strong>Query Expansion Workflow:</strong></p>
                <ol>
                    <li><strong>Initiation:</strong> Define number of perspectives (N).</li>
                    <li><strong>Persona Injection:</strong> Define AI objective (e.g., skeptic, expert).</li>
                    <li><strong>Semantic Diversification:</strong> LLM reframes query to traverse embedding space.</li>
                    <li><strong>Structured Parsing:</strong> Splits output into search list.</li>
                    <li><strong>High-Recall Retrieval:</strong> Parallel search for all variations.</li>
                </ol>
                <p><strong>Reranking Workflow:</strong></p>
                <ul>
                    <li><strong>Over-Retrieval:</strong> Cast a wide net (e.g., fetch 100).</li>
                    <li><strong>Cross-Encoder Scoring:</strong> Process query and document together for deep reasoning.</li>
                    <li><strong>Re-Ordering:</strong> Sort by high-precision score and keep top K.</li>
                </ul>
            </div>
    
            <hr style="border-top: 1px dashed #ccc; margin: 15px 0;">
    
            <div class="subsection">
                <span class="subsection-title">C. Strategic Application Matrix</span>
                <p><strong>Query Expansion:</strong> Use when finding concepts + synonyms. <br>Goal: <strong>Recall</strong>.</p>
                <p><strong>Self-Querying:</strong> Use when finding concepts + strict metadata constraints.<br>Goal: <strong>Precision & Security</strong>.</p>
                <p><strong>Hybrid Approach:</strong> Use for concepts + synonyms + constraints.<br>Goal: <strong>High-stakes retrieval</strong>.</p>
            </div>
        </div>
    </details>

  </div>
</div>
</body>
</html>