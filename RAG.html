<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Part III: RAG Architectures // Study Guide</title>
<style>
    :root {
        --bg-color: #000000;
        --text-color: #00ff41;
        --accent-color: #00ff41;
        --dim-color: #003b00;
        --border-color: #00ff41;
        --font-main: 'Courier New', Courier, monospace;
        --font-header: 'Arial Black', Impact, sans-serif;
    }

    * { box-sizing: border-box; }

    body {
        margin: 0;
        padding: 0;
        background-color: var(--bg-color);
        color: var(--text-color);
        font-family: var(--font-main);
        line-height: 1.5;
        overflow-x: hidden;
    }

    /* --- VISUALS --- */
    .dither-layer {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        z-index: -1;
        background-image: radial-gradient(circle, #003b00 1px, transparent 1px);
        background-size: 4px 4px;
        opacity: 0.4;
    }

    .scanlines {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        background: linear-gradient(to bottom, rgba(0, 255, 65, 0), rgba(0, 255, 65, 0) 50%, rgba(0, 20, 0, 0.2) 50%, rgba(0, 20, 0, 0.2));
        background-size: 100% 4px;
        pointer-events: none;
        z-index: 9999;
    }

    .container {
        max-width: 900px;
        width: 100%;
        margin: 0 auto;
        padding: 40px 20px;
        border-left: 2px dashed var(--dim-color);
        border-right: 2px dashed var(--dim-color);
        background-color: rgba(0, 10, 0, 0.9);
        min-height: 100vh;
    }

    /* --- TYPOGRAPHY --- */
    h1 {
        font-family: var(--font-header);
        text-transform: uppercase;
        font-size: 2.5rem;
        border-bottom: 5px solid var(--accent-color);
        margin-bottom: 40px;
        color: var(--accent-color);
        text-align: center;
        text-shadow: 0px 0px 8px var(--accent-color);
        word-wrap: break-word;
    }

    h3 { margin-top: 0; color: var(--accent-color); text-transform: uppercase; }
    strong { color: var(--accent-color); text-decoration: underline; }
    em { font-style: normal; color: #50c878; border-bottom: 1px dotted var(--dim-color); }

    /* --- ACCORDION STYLES --- */
    /* Outer Parts */
    details.part {
        margin-bottom: 30px;
        border: 2px solid var(--border-color);
        background: #000;
        box-shadow: 6px 6px 0px var(--dim-color);
        transition: transform 0.1s;
    }
    details.part[open] { box-shadow: 4px 4px 0px var(--dim-color); transform: translate(2px, 2px); }
    details.part > summary {
        font-family: var(--font-header);
        font-size: 1.5rem;
        padding: 15px 20px;
        background-color: var(--accent-color);
        color: var(--bg-color);
        cursor: pointer;
        list-style: none;
        text-transform: uppercase;
        position: relative;
    }
    details.part > summary::-webkit-details-marker { display: none; }
    details.part > summary::after { content: '+'; position: absolute; right: 20px; font-weight: 900; }
    details.part[open] > summary::after { content: '-'; }
    .part-content { padding: 20px; border-top: 2px solid var(--border-color); }

    /* Inner Sections */
    details.section {
        margin-bottom: 15px;
        border: 1px solid var(--dim-color);
        background: #050505;
    }
    details.section > summary {
        font-family: var(--font-main);
        font-weight: bold;
        padding: 12px;
        background: #0a0a0a;
        color: var(--text-color);
        cursor: pointer;
        list-style: none;
        border-bottom: 1px solid transparent;
        text-transform: uppercase;
        font-size: 1.1rem;
    }
    details.section > summary:hover { background: var(--dim-color); color: var(--accent-color); }
    details.section[open] > summary {
        border-bottom: 1px solid var(--dim-color);
        background: #0f0f0f;
        color: var(--accent-color);
        text-shadow: 0px 0px 5px var(--accent-color);
    }
    .section-content { padding: 20px; }

    /* Subsections */
    .subsection {
        margin-bottom: 25px;
        border-left: 4px solid var(--dim-color);
        padding-left: 15px;
    }
    .subsection-title {
        background: var(--dim-color);
        color: var(--accent-color);
        padding: 2px 6px;
        font-weight: bold;
        text-transform: uppercase;
        display: inline-block;
        margin-bottom: 10px;
        font-size: 0.9rem;
    }

    p { margin-bottom: 12px; margin-top: 0; text-align: justify; }
    ul { padding-left: 20px; margin-bottom: 15px; }
    li { margin-bottom: 5px; }

    .code-block {
        background: #020a02;
        border: 1px dashed var(--dim-color);
        padding: 10px;
        margin: 10px 0;
        font-family: 'Courier New', monospace;
        color: var(--accent-color);
        overflow-x: auto;
        white-space: pre-wrap;
    }

    /* --- INTERACTIVE: EYE BUTTON & VIEWPORT --- */
    
    .eye-btn {
        position: relative;
        width: 28px; height: 28px;
        background: #000;
        border: 1px solid var(--accent-color);
        cursor: pointer;
        padding: 4px;
        display: inline-flex;
        align-items: center; justify-content: center;
        margin-left: 8px;
        vertical-align: bottom;
        transition: transform 0.1s;
    }
    .eye-btn svg { width: 100%; height: 100%; fill: var(--accent-color); }
    .eye-btn:hover {
        background: var(--accent-color);
        transform: translate(-1px, -1px);
        box-shadow: 2px 2px 0px var(--dim-color);
    }
    .eye-btn:hover svg { fill: #000; }

    .dither-bg {
        background-image: 
            linear-gradient(45deg, var(--dim-color) 25%, transparent 25%), 
            linear-gradient(-45deg, var(--dim-color) 25%, transparent 25%), 
            linear-gradient(45deg, transparent 75%, var(--dim-color) 75%), 
            linear-gradient(-45deg, transparent 75%, var(--dim-color) 75%);
        background-size: 4px 4px;
    }

    .retro-viewport {
        position: fixed;
        top: 50%; left: 50%;
        transform: translate(-50%, -50%);
        width: 80vw; height: 80vh;
        max-width: 900px; max-height: 700px;
        background-color: #000;
        border: 2px solid var(--accent-color);
        box-shadow: 0 0 50px rgba(0, 50, 0, 0.8);
        display: flex; flex-direction: column;
        z-index: 10000;
        visibility: hidden; opacity: 0;
        pointer-events: none;
        transition: opacity 0.2s;
        resize: both; overflow: hidden;
    }
    .retro-viewport.active { visibility: visible; opacity: 1; pointer-events: auto; }

    .vp-header {
        background: var(--accent-color);
        color: #000;
        padding: 5px 10px;
        font-weight: bold;
        font-family: var(--font-header);
        display: flex; justify-content: space-between;
        align-items: center;
        border-bottom: 2px solid #000;
        cursor: default;
    }
    .vp-close {
        background: #000; color: var(--accent-color);
        border: 1px solid #000; font-weight: 900; 
        cursor: pointer; font-family: var(--font-main);
    }
    .vp-close:hover { background: #fff; color: #000; }
    
    .vp-body { flex-grow: 1; position: relative; background: #000; }
    .vp-body iframe { width: 100%; height: 100%; border: none; }

    /* --- RESPONSIVE --- */
    @media (max-width: 600px) {
        h1 { font-size: 1.8rem; border-bottom-width: 3px; }
        details.part > summary { font-size: 1.1rem; padding: 12px; }
        details.section > summary { font-size: 0.9rem; }
        .container { padding: 10px; border: none; }
        .part-content, .section-content { padding: 10px; }
        p { text-align: left; }
        .retro-viewport { width: 95vw; height: 60vh; }
    }
</style>
</head>
<body>
<div class="dither-layer"></div>
<div class="scanlines"></div>
<div class="container">
<h1>Part III: RAG Architectures</h1>

<div class="part-content">
        
        <details class="section">
            <summary>1. RAG Overview & Modules</summary>
            <div class="section-content">
                <p><strong>RAG:</strong> Pulling new, updated, tailored information from a vector store to concatenate as context to a user prompt, before feeding a foundational model.</p>
                <p><strong>A RAG system is composed of three main modules:</strong></p>
                <ul>
                    <li>Ingestion pipeline: A batch or streaming pipeline used to populate the vector DB</li>
                    <li>Retrieval pipeline: A module that queries the vector DB and retrieves relevant entries to the user’s input</li>
                    <li>Generation pipeline: The layer that uses the retrieved data to augment the prompt and an LLM to generate answers</li>
                </ul>
                
                <div class="subsection">
                    <span class="subsection-title">HOW ARE MODULES CONNECTED OVERVIEW</span>
                    <ol>
                        <li>On the backend side, the ingestion pipeline runs either on a schedule or constantly to populate the vector DB with external data.</li>
                        <li>On the client side, the user asks a question.</li>
                        <li>The question is passed to the retrieval module, which preprocesses the user’s input and queries the vector DB.</li>
                        <li>The generation pipelines use a prompt template, user input, and retrieved context to create the prompt.</li>
                        <li>The prompt is passed to an LLM to generate the answer.</li>
                        <li>The answer is shown to the user.</li>
                    </ol>
                </div>
            </div>
        </details>

        <details class="section">
            <summary>2. RAG: Chunking</summary>
            <div class="section-content">
                <p>Chunking is the process of splitting large documents into smaller, discrete segments. In RAG systems, it is essential for:</p>
                <ul>
                    <li><strong>Context Limits:</strong> Ensures text fits within an LLM’s token constraints.</li>
                    <li><strong>Retrieval Precision:</strong> Improves semantic search by focusing on specific topics rather than broad documents.</li>
                    <li><strong>Relevancy:</strong> Helps the model generate accurate answers by providing only the most pertinent context.</li>
                </ul>
                <hr>
                <ul>
                    <li>
                        <strong>Fixed-size Chunking:</strong> Slices text into hard segments based on a strict token or character limit (e.g., 512 tokens). While computationally efficient, it ignores semantic structure, often breaking sentences mid-thought. To mitigate context loss at the edges, a "sliding window" overlap (10-20%) is applied.
                        <ul>
                            <li><em>Example:</em> Processing a raw server log file. You blindly cut the text every 500 characters, regardless of where the line ends.</li>
                            <li><em>When to use:</em> Ideal for uniform data streams or simple tasks where computational speed is the priority and semantic context is less critical (e.g., n-gram analysis).</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Recursive Chunking:</strong> Iteratively breaks down text using a hierarchy of separators to fit specific size limits. It attempts to split by largest structural elements first (like paragraphs), then sentences, then words.
                        <ul>
                            <li><em>Example:</em> An article is split first by double newlines (paragraphs). If a paragraph is still too big, it splits by periods (sentences).</li>
                            <li><em>When to use:</em> The "default" best choice for general prose, articles, and essays. It respects natural reading flow, keeping related ideas (paragraphs) intact.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Content-aware / Syntactic Chunking:</strong> Leverages the distinct formatting logic of the source file to define boundaries. For code, it splits by functions or classes; for Markdown or HTML, it splits by headers or tags.
                        <ul>
                            <li><em>Example:</em> Splitting a Python script by <code>def</code> blocks or an HTML file by <code>&lt;div&gt;</code> tags, ensuring no function is cut in half.</li>
                            <li><em>When to use:</em> Essential for structured documents like Code, Markdown, or JSON. It prevents breaking syntax, ensuring the retrieved chunk is valid and executable.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Semantic Chunking:</strong> Semantic chunking splits text into sentences and converts them to embeddings to assess similarity (usually via cosine). Chunks grow as long as sentences stay semantically close; once distance exceeds a threshold, a new chunk starts. This linear process preserves document order and context for accurate retrieval.
                        <ul>
                            <li><em>Example:</em> A transcript moves from discussing "Weather" to "Stocks." The system detects the topic shift via embeddings and cuts the chunk exactly there.</li>
                            <li><em>When to use:</em> Best for RAG systems requiring high precision. It ensures a chunk contains only one distinct concept, reducing noise for the LLM.</li>
                        </ul>
                    </li>
                </ul>
            </div>
        </details>

        <details class="section">
            <summary>3. RAG: Embedding</summary>
            <div class="section-content">
                <p><strong>Dense Embeddings (Bi-Encoders):</strong> Foundation for semantic search. Captures abstract meaning by collapsing an entire sequence into a single "summary" vector.<br>
                <strong>When to use:</strong> Use this when the intent matters more than specific words. It bridges the gap between synonyms and related concepts by mapping them to the same mathematical space, making it the bedrock of modern semantic search, though it may lose granular word-level nuance.</p>
        
                <p><strong>Sparse Embeddings:</strong> Foundation for lexical search. High-dimensional vectors mapping to specific tokens. Essential for exact keyword matching.<br>
                <strong>When to use:</strong> Use this for precision-heavy tasks where exact keyword matching is non-negotiable. While dense models might "hallucinate" a similar concept, sparse embeddings (like BM25) ensure you find the exact string of characters you typed.</p>
        
                <p><strong>Contextualized Token Embeddings (Late Interaction):</strong> Foundation for fine-grained matching (e.g., BERT, ColBERT). Unlike dense summaries, this generates separate, unique vectors for every token based on its neighbors.<br>
                <strong>Example:</strong> Distinguishing between "bank" in "river bank" vs. "investment bank."<br>
                <strong>When to use:</strong> Best for complex queries where word order and situational meaning change the intent. It allows for "late interaction" to find highly granular matches between specific parts of a query and a document.</p>
        
                <p><strong>Contrastive Learning Embeddings:</strong> Foundation for similarity learning. Pulls similar examples together, pushes dissimilar apart.<br>
                <strong>Example:</strong> Training a model by showing it pairs of "duplicate" customer reviews to pull them together while pushing "unrelated" reviews away.<br>
                <strong>When to use:</strong> Use this during the training phase to refine a model's judgment. It’s the "coach" that teaches the embedding space how to distinguish between subtly different items.</p>
            </div>
        </details>

        <details class="section">
            <summary>4. RAG Ingestion: Walkthrough</summary>
            <div class="section-content">
                <ol>
                    <li><strong>Pull in the raw data (Data extraction/Ingestion):</strong> Collect documents from databases, PDFs, APIs, etc.</li>
                    <li><strong>Clean it up (Cleaning layer):</strong> Fix messy text: remove weird characters, strip URLs, delete headers/footers.</li>
                    <li><strong>Break into smaller pieces (Chunking/Splitting):</strong> Split large documents into 300-800 word chunks. Smart chunking keeps complete thoughts together.</li>
                    <li><strong>Turn into vectors (Embedding):</strong> Send chunks to an embedding model. Text becomes numerical vectors capturing meaning.</li>
                    <li><strong>Save in vector database (Loading):</strong> Store vectors + metadata (source URL, date, title) in a vector DB.</li>
                </ol>
                <p><strong>Result:</strong> When users ask questions, the system searches vectors for relevant chunks, adds them to the prompt, and the LLM generates accurate, grounded answers.</p>
                <p><strong>In short:</strong> Raw documents &rarr; cleaned &rarr; chunked &rarr; vectorized &rarr; stored &rarr; ready for AI retrieval.</p>
            </div>
        </details>

        <details class="section">
            <summary>5. Indexing Methods in a Vector Database</summary>
            <div class="section-content">
                <p><strong>What is a Vector DB:</strong> Traditional databases look for exact word matches, but vector DBs find data that is <em>similar</em> to your query. They organize information as numeric vectors using specialized indexes.</p>
                
                <div class="subsection">
                    <span class="subsection-title">HNSW (Hierarchical Navigable Small World)</span>
                    <button class="eye-btn" onclick="let vp = document.querySelector('.retro-viewport'); vp.querySelector('iframe').src='RAG/HNSW.html'; vp.classList.add('active');">
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                            <path d="M12 4.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5zM12 17c-2.76 0-5-2.24-5-5s2.24-5 5-5 5 2.24 5 5-2.24 5-5 5zm0-8c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/>
                        </svg>
                    </button>
                    <p>Constructs a multi-layered graph structure. Upper layers contain sparse nodes for rapid "greedy" traversal. Lower layers are denser for fine-grained navigation. Ensures logarithmic search complexity trading high memory usage for speed.</p>
                </div>
        
                <div class="subsection">
                    <span class="subsection-title">LSH (Locality-Sensitive Hashing)</span>
                    <button class="eye-btn" onclick="let vp = document.querySelector('.retro-viewport'); vp.querySelector('iframe').src='RAG/LSH.html'; vp.classList.add('active');">
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                            <path d="M12 4.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5zM12 17c-2.76 0-5-2.24-5-5s2.24-5 5-5 5 2.24 5 5-2.24 5-5 5zm0-8c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/>
                        </svg>
                    </button>
                    <p>Projects vectors onto random hyperplanes to generate binary signatures. Vectors on the same side land in the same "bucket". Querying becomes an O(1) lookup.</p>
                </div>
        
                <div class="subsection">
                    <span class="subsection-title">Product Quantization (PQ)</span>
                    <button class="eye-btn" onclick="let vp = document.querySelector('.retro-viewport'); vp.querySelector('iframe').src='RAG/PQ.html'; vp.classList.add('active');">
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                            <path d="M12 4.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5zM12 17c-2.76 0-5-2.24-5-5s2.24-5 5-5 5 2.24 5 5-2.24 5-5 5zm0-8c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/>
                        </svg>
                    </button>
                    <ul>
                        <li>Quantization approximates precise values using limited "centroids."</li>
                        <li>PQ is vital when datasets exceed RAM limits. It acts as a rapid <strong>pre-filter</strong>.</li>
                        <li>Breaks vectors into sub-parts, quantizing each to create a compact code. The <strong>Signature Matrix</strong> stores these compressed IDs.</li>
                    </ul>
                </div>
        
                <div class="subsection">
                    <span class="subsection-title">Random Projection (RP)</span>
                    <button class="eye-btn" onclick="let vp = document.querySelector('.retro-viewport'); vp.querySelector('iframe').src='RAG/random_projection.html'; vp.classList.add('active');">
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                            <path d="M12 4.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5zM12 17c-2.76 0-5-2.24-5-5s2.24-5 5-5 5 2.24 5 5-2.24 5-5 5zm0-8c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/>
                        </svg>
                    </button>
                    <p>Reduces dimensionality by multiplying vectors with a fixed random matrix. Maps data to lower-dimensional space while preserving relative distances.</p>
                </div>
            </div>
        </details>

        <details class="section">
            <summary>6. Advanced Retrieval Strategies: Self-Querying, Expansion & Reranking</summary>
            <div class="section-content">
                
                <div class="subsection">
                    <span class="subsection-title">A. Self-Querying / Filtered Vector Search</span>
                    <p><em>Best for finding "x" with strict constraints "y" (Focus: Precision & Security).</em></p>
                    <p><strong>Process:</strong></p>
                    <ol>
                        <li><strong>Scope and Configuration:</strong> Loads Metadata Schema.</li>
                        <li><strong>Schema-Based Extraction:</strong> Maps text to structured categories (e.g., author: Paul).</li>
                        <li><strong>Entity Resolution:</strong> Resolves names to UUIDs.</li>
                        <li><strong>Query Enrichment:</strong> Combines semantic text with hard identifiers.</li>
                        <li><strong>Filtered Retrieval:</strong> DB executes search with strict metadata gates.</li>
                    </ol>
                    <p><strong>Technical Breakdown:</strong></p>
                    <ul>
                        <li><strong>Metadata Schema Definition:</strong> Tag vectors during ingestion.</li>
                        <li><strong>Self-Query Phase:</strong> LLM extracts filters (e.g., Year: 2024).</li>
                        <li><strong>Pre-Filtering Execution:</strong> Masks non-matching documents <em>before</em> similarity calculation.</li>
                        <li><strong>Vector Similarity Search:</strong> Calculates distance only on surviving candidates.</li>
                    </ul>
                </div>
        
                <hr style="border-top: 1px dashed #ccc; margin: 15px 0;">
        
                <div class="subsection">
                    <span class="subsection-title">B. Query Expansion & Reranking</span>
                    <p><em>Best for finding "x" and synonyms (Focus: Recall).</em></p>
                    <p><strong>Query Expansion Workflow:</strong></p>
                    <ol>
                        <li><strong>Initiation:</strong> Define number of perspectives (N).</li>
                        <li><strong>Persona Injection:</strong> Define AI objective (e.g., skeptic, expert).</li>
                        <li><strong>Semantic Diversification:</strong> LLM reframes query to traverse embedding space.</li>
                        <li><strong>Structured Parsing:</strong> Splits output into search list.</li>
                        <li><strong>High-Recall Retrieval:</strong> Parallel search for all variations.</li>
                    </ol>
                    <p><strong>Reranking Workflow:</strong></p>
                    <ul>
                        <li><strong>Over-Retrieval:</strong> Cast a wide net (e.g., fetch 100).</li>
                        <li><strong>Cross-Encoder Scoring:</strong> Process query and document together for deep reasoning.</li>
                        <li><strong>Re-Ordering:</strong> Sort by high-precision score and keep top K.</li>
                    </ul>
                </div>
        
                <hr style="border-top: 1px dashed #ccc; margin: 15px 0;">
        
                <div class="subsection">
                    <span class="subsection-title">C. Strategic Application Matrix</span>
                    <p><strong>Query Expansion:</strong> Use when finding concepts + synonyms. <br>Goal: <strong>Recall</strong>.</p>
                    <p><strong>Self-Querying:</strong> Use when finding concepts + strict metadata constraints.<br>Goal: <strong>Precision & Security</strong>.</p>
                    <p><strong>Hybrid Approach:</strong> Use for concepts + synonyms + constraints.<br>Goal: <strong>High-stakes retrieval</strong>.</p>
                </div>
            </div>
        </details>

        <details class="section">
            <summary>7. RAG Evaluation</summary>
            <div class="section-content">
                <p>Standard LLM tests check internal knowledge. <strong>RAG evaluation</strong> assesses the whole system: <strong>Retrieval</strong> (finding facts) and <strong>Generation</strong> (using them). It measures Faithfulness, Answer Relevance, and Context Relevance to ensure the output is grounded in the source.</p>
                
                <div class="subsection">
                    <span class="subsection-title">The RAGAS Framework</span>
                    <p><strong>RAGAS (Retrieval-Augmented Generation Assessment)</strong> is a framework used to quantify the performance of your RAG pipeline. Ragas uses <strong>LLM-as-a-judge</strong> to evaluate the relationship between the <strong>Question</strong>, the <strong>Context</strong> (retrieved facts), and the <strong>Answer</strong>.</p>
                    
                </div>

                <div class="subsection">
                    <span class="subsection-title">1. Faithfulness</span>
                    <p><strong>Core Concept:</strong> The primary metric for detecting hallucinations. It strictly measures <strong>grounding</strong>: the extent to which the generated answer is derived <em>only</em> from the retrieved context, ignoring the model's pre-trained knowledge.</p>
                    <p><strong>The "Judge" Process:</strong></p>
                    <ul>
                        <li><strong>Statement Extraction:</strong> The LLM breaks the answer into atomic statements (simple, standalone claims) to prevent complex sentences from hiding inaccuracies.</li>
                        <li><strong>Verification:</strong> The LLM acts as a binary classifier, cross-referencing each atomic statement against the Contexts to see if it can be inferred entirely from provided text.</li>
                    </ul>
                    <p><strong>The Calculation:</strong> <code>Faithfulness = # of verified statements / total number of statements</code>.</p>
                    <p><strong>Why It Matters:</strong> Critical for enterprise apps (legal/medical). If the context doesn't say it, the model shouldn't say it.</p>
                </div>

                <div class="subsection">
                    <span class="subsection-title">2. Answer Relevancy</span>
                    <p><strong>Core Concept:</strong> Measures the pertinence of the response to the user's initial query. Unlike Faithfulness, this does <em>not</em> check factual correctness; it penalizes incomplete, redundant, or drifting answers.</p>
                    <p><strong>The "Judge" Process (Reverse Engineering):</strong></p>
                    <ul>
                        <li><strong>Question Generation:</strong> The LLM analyzes the generated Answer and attempts to generate questions that <em>would</em> result in this answer.</li>
                        <li><strong>Embedding Similarity:</strong> RAGAS converts the Original User Question and Generated Questions into vector embeddings and calculates the cosine similarity.</li>
                    </ul>
                    <p><strong>The Calculation:</strong> The score is the mean cosine similarity. A score closer to 1 means the generated answer maps perfectly back to the original intent.</p>
                    <p><strong>Why It Matters:</strong> A low score indicates the model is "hedging" or providing generic summaries rather than directly answering the specific prompt.</p>
                </div>

                <div class="subsection">
                    <span class="subsection-title">3. Context Precision</span>
                    <p><strong>Core Concept:</strong> Evaluates if the most relevant text segments ("chunks") are ranked at the top. Since LLMs have limited context windows, the retriever must prioritize high-value excerpts.</p>
                    <p><strong>The "Judge" Process:</strong> The LLM compares retrieved chunks against Ground Truth to classify them as Relevant or Irrelevant, then checks if "Relevant" chunks appear before "Irrelevant" ones.</p>
                    <p><strong>The Calculation:</strong> Uses Average Precision, calculating the mean precision score at every rank position where a relevant chunk is found.</p>
                </div>

                <div class="subsection">
                    <span class="subsection-title">HOW: The Evaluation Workflow</span>
                    <ol>
                        <li><strong>Data Preparation:</strong> Organize RAG outputs into a dataset (Question, Contexts, Answer, Ground Truth).</li>
                        <li><strong>The Evaluation Loop:</strong> Initialize an Evaluator LLM (e.g., GPT-4o) and call the <code>evaluate()</code> function.</li>
                        <li><strong>Under the Hood:</strong> The judge performs specific linguistic tasks: <em>Extraction</em> (claims), <em>Verification</em> (logic check), and <em>Back-Projection</em> (relevance check).</li>
                        <li><strong>Output:</strong> A dataframe or dictionary with scores (0 to 1) identifying exactly where the system is failing—whether it's the search (retriever) or the writing (generator).</li>
                    </ol>
                </div>
            </div>
        </details>

        <details class="section">
            <summary>8. End to End Optimized RAG Inference Flow</summary>
            <div class="section-content">
                <div class="subsection">
                    <span class="subsection-title">1. The Core RAG Synthesis</span>
                    <ul>
                        <li><strong>Retrieval & Context Mapping:</strong> ContextRetriever fetches and maps chunks.</li>
                        <li><strong>The Prompt Factory:</strong> Constructs "Augmented Prompt" with template.</li>
                        <li><strong>Inference Execution:</strong> Sends to LLM for grounded answer.</li>
                    </ul>
                </div>
                <div class="subsection">
                    <span class="subsection-title">2. Optimization: Conversation Memory</span>
                    <p>Uses Sliding Window or Summarization Strategy to handle stateless LLMs.</p>
                </div>
                <div class="subsection">
                    <span class="subsection-title">3. Optimization: Intelligent Routing</span>
                    <p>Semantic Router directs searches to specific repositories (e.g., Code vs Articles) to save cost.</p>
                </div>
                <div class="subsection">
                    <span class="subsection-title">4. Optimization: Hybrid Search</span>
                    <p>Combines Vector Search and BM25 using score normalization and weighted merging.</p>
                </div>
                <div class="subsection">
                    <span class="subsection-title">5. Optimization: Multi-Index Vectors</span>
                    <p>Embeds metadata (Platform, Date) into the vector index to weigh authority/recency.</p>
                </div>
            </div>
        </details>

</div>
</div>

<div class="retro-viewport">
    <div class="vp-header">
        <span>ARCHIVE_VIEWER_V1.0</span>
        <button class="vp-close" onclick="document.querySelector('.retro-viewport').classList.remove('active'); document.querySelector('.retro-viewport iframe').src='';">X</button>
    </div>
    <div class="vp-body">
        <iframe src=""></iframe>
    </div>
</div>

</body>
</html>