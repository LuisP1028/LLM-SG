<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Part IV: Supervised Fine-Tuning // Study Guide</title>
<script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
    };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<style>
    :root {
        --bg-color: #000000;
        --text-color: #00ff41;
        --accent-color: #00ff41;
        --dim-color: #003b00;
        --border-color: #00ff41;
        --font-main: 'Courier New', Courier, monospace;
        --font-header: 'Arial Black', Impact, sans-serif;
    }

    * { box-sizing: border-box; }

    body {
        margin: 0;
        padding: 0;
        background-color: var(--bg-color);
        color: var(--text-color);
        font-family: var(--font-main);
        line-height: 1.5;
        overflow-x: hidden;
    }

    /* --- VISUALS --- */
    .dither-layer {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        z-index: -1;
        background-image: radial-gradient(circle, #003b00 1px, transparent 1px);
        background-size: 4px 4px;
        opacity: 0.4;
    }

    .scanlines {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        background: linear-gradient(to bottom, rgba(0, 255, 65, 0), rgba(0, 255, 65, 0) 50%, rgba(0, 20, 0, 0.2) 50%, rgba(0, 20, 0, 0.2));
        background-size: 100% 4px;
        pointer-events: none;
        z-index: 9999;
    }

    .container {
        max-width: 900px;
        width: 100%;
        margin: 0 auto;
        padding: 40px 20px;
        border-left: 2px dashed var(--dim-color);
        border-right: 2px dashed var(--dim-color);
        background-color: rgba(0, 10, 0, 0.9);
        min-height: 100vh;
    }

    /* --- TYPOGRAPHY --- */
    h1 {
        font-family: var(--font-header);
        text-transform: uppercase;
        font-size: 2.5rem;
        border-bottom: 5px solid var(--accent-color);
        margin-bottom: 40px;
        color: var(--accent-color);
        text-align: center;
        text-shadow: 0px 0px 8px var(--accent-color);
        word-wrap: break-word;
    }

    h3, h4, h5 { margin-top: 20px; color: var(--accent-color); text-transform: uppercase; }
    strong { color: var(--accent-color); text-decoration: underline; }
    em { font-style: normal; color: #50c878; border-bottom: 1px dotted var(--dim-color); }

    /* --- ACCORDION STYLES --- */
    /* Outer Parts */
    details.part {
        margin-bottom: 30px;
        border: 2px solid var(--border-color);
        background: #000;
        box-shadow: 6px 6px 0px var(--dim-color);
        transition: transform 0.1s;
    }
    details.part[open] { box-shadow: 4px 4px 0px var(--dim-color); transform: translate(2px, 2px); }
    details.part > summary {
        font-family: var(--font-header);
        font-size: 1.5rem;
        padding: 15px 20px;
        background-color: var(--accent-color);
        color: var(--bg-color);
        cursor: pointer;
        list-style: none;
        text-transform: uppercase;
        position: relative;
    }
    details.part > summary::-webkit-details-marker { display: none; }
    details.part > summary::after { content: '+'; position: absolute; right: 20px; font-weight: 900; }
    details.part[open] > summary::after { content: '-'; }
    .part-content { padding: 20px; border-top: 2px solid var(--border-color); }

    /* Inner Sections */
    details.section {
        margin-bottom: 15px;
        border: 1px solid var(--dim-color);
        background: #050505;
    }
    details.section > summary {
        font-family: var(--font-main);
        font-weight: bold;
        padding: 12px;
        background: #0a0a0a;
        color: var(--text-color);
        cursor: pointer;
        list-style: none;
        border-bottom: 1px solid transparent;
        text-transform: uppercase;
        font-size: 1.1rem;
    }
    details.section > summary:hover { background: var(--dim-color); color: var(--accent-color); }
    details.section[open] > summary {
        border-bottom: 1px solid var(--dim-color);
        background: #0f0f0f;
        color: var(--accent-color);
        text-shadow: 0px 0px 5px var(--accent-color);
    }
    .section-content { padding: 20px; }

    /* --- NESTED ACCORDION (TREE VISUALIZATION) --- */
    details.nested-accordion {
        margin-bottom: 5px;
        margin-left: 10px;
        padding-left: 20px; /* Space for the branch line */
        border-left: 2px dashed var(--dim-color); /* The Tree Trunk */
        position: relative;
        background: transparent;
    }

    /* The Horizontal Branch Line */
    details.nested-accordion::before {
        content: '';
        position: absolute;
        top: 18px; /* Approx center of text */
        left: 0;
        width: 15px;
        height: 2px;
        background-color: var(--dim-color);
    }

    details.nested-accordion > summary {
        font-family: var(--font-main);
        font-size: 0.95rem;
        padding: 5px 10px;
        background-color: transparent;
        cursor: pointer;
        list-style: none;
        color: var(--text-color);
        transition: background-color 0.1s, color 0.1s;
        display: block; /* Full width for hover */
    }

    /* HOVER EFFECT: Invert Colors */
    details.nested-accordion > summary:hover {
        background-color: var(--accent-color);
        color: #000000;
        font-weight: bold;
    }

    /* Ensure strong tags inside summary also invert on hover */
    details.nested-accordion > summary:hover strong {
        color: #000000;
        text-decoration: none;
    }

    details.nested-accordion[open] {
        margin-top: 10px;
        margin-bottom: 20px;
    }

    /* Content styling aligned with the tree */
    .accordion-content {
        padding-top: 10px;
        padding-left: 10px;
        border-left: 2px solid var(--dim-color);
        margin-left: -2px; /* Align with dashed trunk */
    }

    /* Subsections */
    .subsection {
        margin-bottom: 25px;
        border-left: 4px solid var(--dim-color);
        padding-left: 15px;
    }
    .subsection-title {
        background: var(--dim-color);
        color: var(--accent-color);
        padding: 2px 6px;
        font-weight: bold;
        text-transform: uppercase;
        display: inline-block;
        margin-bottom: 10px;
        font-size: 0.9rem;
    }

    p { margin-bottom: 12px; margin-top: 0; text-align: justify; }
    ul { padding-left: 20px; margin-bottom: 15px; }
    li { margin-bottom: 5px; }

    .code-block {
        background: #020a02;
        border: 1px dashed var(--dim-color);
        padding: 10px;
        margin: 10px 0;
        font-family: 'Courier New', monospace;
        color: var(--accent-color);
        overflow-x: auto;
        white-space: pre-wrap;
    }

    /* --- RESPONSIVE --- */
    @media (max-width: 600px) {
        h1 { font-size: 1.8rem; border-bottom-width: 3px; }
        details.part > summary { font-size: 1.1rem; padding: 12px; }
        details.section > summary { font-size: 0.9rem; }
        .container { padding: 10px; border: none; }
        .part-content, .section-content { padding: 10px; }
        p { text-align: left; }
    }
</style>
</head>
<body>
<div class="dither-layer"></div>
<div class="scanlines"></div>
<div class="container">
<h1>Part IV: Supervised Fine-Tuning</h1>
<div class="part-content">

    <details class="section" open> <summary>1. Data Strategy & Acquisition</summary> <div class="section-content"> 
        <p>Defining the raw material and strategic goals before processing begins.</p>
        
        <details class="nested-accordion">
            <summary>Essential Dimensions of Data</summary>
            <div class="accordion-content">
                <ul>
                    <li><strong>Accuracy:</strong> Accuracy ensures that the data is factually correct and directly answers the user's specific instruction. </li>
                    <li><strong>Diversity:</strong> Diversity means the dataset must cover a wide variety of topics, writing styles, and lengths. It should represent the many different ways people will actually use the model. </li>
                    <li><strong>Complexity:</strong> Complexity avoids easy or trivial examples that do not challenge the model. Instead, the data should include difficult tasks and multi-step reasoning problems.</li>
                    <li><strong>Data Quantity:</strong> The Hugging Face Hub contains numerous instruction datasets, which can be general-purpose or designed for particular tasks or domains.</li>
                </ul>
            </div>
        </details>

        <details class="nested-accordion">
            <summary>Task vs. Domain Specific Models</summary>
            <div class="accordion-content">
                <p><strong>Task-specific</strong> models focus on performing a single action, such as translation or summarization, often requiring less data and smaller model sizes. For task-specific models, data curation often involves <strong>collecting examples of the desired task from existing datasets or creating new ones.</strong></p>
                <p><strong>Domain-specific</strong> models, however, focus on mastering a specific industry. They <strong>prioritize specialized knowledge and vocabulary</strong>, with data needs varying based on the field's complexity. Domains that are well-represented in the original training data may require less fine-tuning, while those that are more specialized or underrepresented may need more extensive datasets.</p>
            </div>
        </details>

        <details class="nested-accordion">
            <summary>Data Exploration & Generation</summary>
            <div class="accordion-content">
                <h4>Data Exploration</h4>
                <p>Helpful in testing for dataset diversity.</p>
                <p><strong>Statistical Analysis:</strong> Uses NLP libraries like NLTK and spaCy to scan text for vocabulary diversity and bias via tokenization. </p>
                <p><strong>Topic Clustering:</strong> Automatically groups similar documents to uncover hidden themes and trends within large datasets. It converts text into numerical embeddings (vectors) using sentence transformers.</p>
                
                <hr />
                
                <h4>Data Generation</h4>
                <p>When available instruction datasets are not sufficient, custom data creation is necessary. </p>
                <p><strong>How It Works:</strong> Data generation builds custom datasets starting with a <strong>taxonomy</strong>.</p>
                <ul>
                    <li><strong>Taxonomy (The "What"):</strong> Breaking a broad domain into specific sub-capabilities to ensure full coverage (e.g., coding → debugging → loops).</li>
                    <li><strong>Seed (The "How"):</strong> The specific prompt templates used to generate the data.</li>
                </ul>
                <p>These elements combined aid in the generation of massive instruction-response pairs.</p>
        
                <details class="nested-accordion">
                    <summary>Practical Domain Examples</summary>
                    <div class="accordion-content">
                        <p><strong>1. Financial Risk Assessment</strong></p>
                        <ul>
                            <li><strong>Taxonomy:</strong> Corporate Finance → Credit Risk → Liquidity Analysis → Cash Flow Volatility.</li>
                            <li><strong>Seed:</strong> "Analyze the statement for [COMPANY]. Given a [PERCENTAGE] drop in operating cash flow, calculate the new Debt Service Coverage Ratio (DSCR). Suggest two mitigation strategies."</li>
                        </ul>
        
                        <p><strong>2. Cybersecurity Threat Hunting</strong></p>
                        <ul>
                            <li><strong>Taxonomy:</strong> Network Security → Attack Vectors → Phishing → Business Email Compromise (BEC).</li>
                            <li><strong>Seed:</strong> "Identify the [SOCIAL_ENGINEERING_TACTIC] used in this email snippet: '[EMAIL_BODY]'. Rewrite the email to be more subtle by incorporating a [SPECIFIC_URGENCY] trigger."</li>
                        </ul>
        
                        <p><strong>3. Pediatric Medical Triage</strong></p>
                        <ul>
                            <li><strong>Taxonomy:</strong> Emergency Medicine → Respiratory Distress → Asthma → Severity Scoring (PRAM).</li>
                            <li><strong>Seed:</strong> "A [AGE]-year-old presents with [SYMPTOM_1] and [SYMPTOM_2]. Based on a PRAM score of [SCORE], determine if the patient requires immediate [INTERVENTION] or observation."</li>
                        </ul>
                    </div>
                </details>
            </div>
        </details>

        <details class="nested-accordion">
            <summary>Data Augmentation (Evol-Instruct)</summary>
            <div class="accordion-content">
                <p>In this context, <strong>data augmentation</strong> focuses on the <strong>Input</strong> side: upgrading simple prompts into complex training signals.</p>
                
                <hr>
                
                <details class="nested-accordion">
                    <summary>1. Evol-Instruct (Upgrading the Prompt)</summary>
                    <div class="accordion-content">
                        <p>It rewrites simple prompts into complex ones to force the model to think harder or broaden its scope.</p>
                        
                        <h5>Evolution Strategies:</h5>
                        <ul>
                            <li><strong>In-Depth Evolving (Making it Harder):</strong> Increases the difficulty of a specific prompt.
                                <ul>
                                    <li><em>Constraints:</em> Adding strict rules or limits.</li>
                                    <li><em>Deepening:</em> Asking for comprehensive analysis rather than simple facts.</li>
                                    <li><em>Concretizing:</em> Making vague concepts specific.</li>
                                    <li><em>Reasoning Steps:</em> Demanding multi-step logic.</li>
                                    <li><em>Complicating Input:</em> Adding complex formats like code or JSON.</li>
                                </ul>
                            </li>
                            <li><strong>In-Breadth Evolving (Making it Diverse):</strong> Increases variety. It generates completely new, unique instructions inspired by the original ones to cover rare or niche topics.</li>
                        </ul>
                    </div>
                </details>

                <details class="nested-accordion">
                    <summary>2. Evol-Instruct Examples</summary>
                    <div class="accordion-content">
                        <div class="subsection">
                            <span class="subsection-title">Infrastructure</span>
                            <ul>
                                <li><strong>Base Instruction:</strong> Inspect the bridge for damage.</li>
                                <li><strong>In-Depth (Constraint):</strong> Inspect the bridge for micro-fractures in the support pylons using thermal imaging data, citing specific ISO safety standards for load-bearing capacity.</li>
                                <li><strong>In-Breadth (New Topic):</strong> Develop a predictive maintenance schedule for an aging underground sewer network based on soil acidity levels.</li>
                            </ul>
                        </div>
            
                        <div class="subsection">
                            <span class="subsection-title">Defense</span>
                            <ul>
                                <li><strong>Base Instruction:</strong> Analyze satellite imagery.</li>
                                <li><strong>In-Depth (Complicating Input):</strong> Analyze the provided raw JSON telemetry from a surveillance drone to identify camouflaged vehicle heat signatures, ignoring background radiation noise.</li>
                                <li><strong>In-Breadth (New Topic):</strong> Formulate a jamming protocol to disrupt enemy communication channels during a high-altitude paratrooper insertion.</li>
                            </ul>
                        </div>
            
                        <div class="subsection">
                            <span class="subsection-title">Healthcare</span>
                            <ul>
                                <li><strong>Base Instruction:</strong> Diagnose the patient's fever.</li>
                                <li><strong>In-Depth (Reasoning):</strong> Diagnose the fever in a post-transplant patient exhibiting rejection signs, differentiating it from a bacterial infection using the provided blood panel results.</li>
                                <li><strong>In-Breadth (New Topic):</strong> Outline a triage procedure for a mass-casualty event involving exposure to a rare neurotoxin in a metropolitan area.</li>
                            </ul>
                        </div>
            
                        <div class="subsection">
                            <span class="subsection-title">Aerospace</span>
                            <ul>
                                <li><strong>Base Instruction:</strong> Check the landing gear.</li>
                                <li><strong>In-Depth (Constraint):</strong> Troubleshoot the landing gear hydraulic failure occurring specifically at -40°C, proposing a fix that adds no more than 5kg of weight to the assembly.</li>
                                <li><strong>In-Breadth (New Topic):</strong> Calculate the trajectory correction burn required for a probe entering a polar orbit around Europa.</li>
                            </ul>
                        </div>
                    </div>
                </details>
            </div>
        </details>
    </div>
    </details>

    <details class="section"> <summary>2. Data Curation & Refinement</summary> <div class="section-content"> 
        <p>Filtering and evaluating the raw data to ensure high quality before packaging.</p>

        <details class="nested-accordion">
            <summary>Data Curation: Rule-Based Filtering</summary>
            <div class="accordion-content">
                <p><strong>Rule-based filtering</strong> is a quality control method that uses explicit, pre-set rules to automatically keep or remove data samples. Its speed and efficiency allow for rapid application to large volumes of data, making it highly scalable.</p>
                <ul>
                    <li><strong>Length filtering:</strong> This rule manages data quality by setting minimum and maximum size limits. It removes responses that are too short to be meaningful or too long and repetitive.</li>
                    <li><strong>Keyword exclusion:</strong> This rule filters data based on specific content.</li>
                    <li><strong>Format checking:</strong> This rule validates the structure of the data. It ensures that samples, particularly technical ones like computer code or JSON, follow specific formatting requirements so they remain consistent and usable.</li>
                </ul>
            </div>
        </details>
    
        <details class="nested-accordion">
            <summary>Data Deduplication & Decontamination</summary>
            <div class="accordion-content">
                <p>In practice, these steps are the "safeguards" of a pipeline, ensuring the model doesn't just memorize patterns or "leak" answers.<strong>Decontamination</strong> acts as a "cheat check," where the training set is compared against benchmark test sets (like MMLU); any training sample too similar to a test question is purged to ensure the final evaluation measures true reasoning, not memorization.</p>
                

                <details class="nested-accordion">
                    <summary>Exact Deduplication</summary>
                    <div class="accordion-content">
                        <p><strong>Exact deduplication</strong> removes identical entries by normalizing data and comparing unique hash codes (e.g., <strong>SHA-256</strong>). If hashes match, the data is considered a duplicate.</p>
                        <ul>
                            <li><strong>Precision:</strong> Extremely high for identical copies.</li>
                            <li><strong>Limitation:</strong> It is "brittle"—it misses documents with even a single character difference, typos, or semantically similar content.</li>
                        </ul>
                    </div>
                </details>
    
                <details class="nested-accordion">
                    <summary>Fuzzy Deduplication</summary>
                    <div class="accordion-content">
                        <p><strong>Fuzzy deduplication</strong> detects <em>near-duplicates</em> using <strong>MinHash</strong>. This process involves breaking data into "shingle" fingerprints to compare documents that are similar but not identical.</p>
            
                        <h4>1. Shingling & N-grams</h4>
                        <p><strong>Shingles</strong> are overlapping subsequences used to convert text into a mathematical set. For example, the phrase "red car" might become the set: <code>{"red", "ed ", " ca", "car"}</code>.</p>
                        <p>These are often categorized as <strong>n-grams</strong> (contiguous sequences of <em>n</em> items):</p>
                        <ul>
                            <li><strong>Character n-gram:</strong> "Code" (n=3) -> <code>{"Cod", "ode"}</code></li>
                            <li><strong>Word n-gram:</strong> "My code runs" (n=2) ->  <code>{"My code", "code runs"}</code></li>
                        </ul>
            
                        <h4>2. Jaccard Similarity Index</h4>
                        <p>The <strong>Jaccard Similarity Index</strong> measures the resemblance between two sets. It is calculated by dividing the size of the <strong>intersection</strong> (shared shingles) by the size of the <strong>union</strong> (total unique shingles).</p>
            
                        <blockquote>
                            The formula for Jaccard Similarity is:
                            $$J(A, B) = \frac{|A \cap B|}{|A \cup B|}$$
                        </blockquote>
            
                        <ul>
                            <li>A score of <strong>1.0</strong> indicates identical sets (complete overlap).</li>
                            <li>A score of <strong>0.0</strong> indicates no overlap whatsoever.</li>
                        </ul>
                    </div>
                </details>
            </div>
        </details>
    
        <details class="nested-accordion">
            <summary>Data Quality Evaluation (LLM-as-a-judge)</summary>
            <div class="accordion-content">
                <p>Measures attributes like <stong>accuracy, diversity, and complexity</stong> to ensure datasets are fit for training models.</p>
                
        
                <details class="nested-accordion">
                    <summary>Response Selection Methods</summary>
                    <div class="accordion-content">
                        <p>When using an LLM to evaluate data, there are two primary methods:</p>
                        <ul>
                            <li><strong>Absolute Scoring:</strong> The LLM assigns a 1–5 or "Good/Bad" rating to a single response. It’s fast but often inconsistent across different prompts or sessions.</li>
                            <li><strong>Pairwise Ranking [Best]:</strong> The LLM compares two responses (A vs. B) to pick a winner. This is the gold standard for DPO because it mimics human decision-making and produces more stable, relative signals.</li>
                        </ul>
                    </div>
                </details>
        
                <details class="nested-accordion">
                    <summary>Evaluation Methods</summary>
                    <div class="accordion-content">
                        <ul>
                            <li><strong>CoT + Pairwise Ranking:</strong> Use when the task is highly subjective or creative (e.g., poetry, persona-mimicry).
                                <br><em>Strength:</em> Forces logical justification. Since no "answer key" exists, the judge's own reasoning process ensures it weighs complex trade-offs—like creativity vs. clarity—before picking a winner. It prevents reliance on "vibes" or length by building an independent logical path.
                            </li>
                            <li><strong>Ground Truth + Pairwise Ranking:</strong> Use when there is a definitive "correct" answer (e.g., Python scripts, calculus, or history).
                                <br><em>Strength:</em> Acts as an immutable anchor. It eliminates hallucinations by providing the judge with the "answer key," forcing it to penalize confident but incorrect logic. It shifts the task from "Which sounds better?" to "Which is more correct?"
                            </li>
                            <li><strong>The Rubric + Pairwise Ranking:</strong> Use when the task is constrained by specific requirements but lacks a single "right" answer (e.g., "Summarize this for a 5-year-old").
                                <br><em>Strength:</em> Prevents "goalpost shifting." By defining the ideal criteria first, the judge resists favoring superficial traits like politeness or length over actual compliance, leading to a much cleaner training signal.
                            </li>
                        </ul>
                        <p><strong>Biases of LLM-as-a-judge:</strong></p>
                        <ul>
                            <li><strong>Position Bias:</strong> Favoring the first answer presented.</li>
                            <li><strong>Verbosity Bias:</strong> Preferring longer responses.</li>
                            <li><strong>Self-Preference:</strong> Rating their own model family higher.</li>
                        </ul>
                        <p>Counter these by randomizing order, length normalization, and using diverse judges.</p>  
                    </div>
                </details>

                <details class="nested-accordion">
                    <summary>Implementation: UltraFeedback Workflow</summary>
                    <div class="accordion-content">
                        <p>It upgrades the <strong>Answer</strong> by generating multiple responses and selecting the best one.</p>
                        
                        <h5>The Workflow:</h5>
                        <ul>
                            <li><strong>The Inputs:</strong> Generate multiple answers (e.g., 4) for one question using different models.</li>
                            <li><strong>The Rubric:</strong> Provide a "Judge" LLM with a specific scorecard (e.g., "Score 1-5 on technical accuracy and safety").</li>
                            <li><strong>The Selection:</strong> The Judge evaluates the responses against the rubric and keeps only the highest-scoring answer for the final dataset.</li>
                        </ul>
                
                        <hr />
                
                        <h5>How It Works:</h5>
                        <ul>
                            <li><strong>Direct Input:</strong> It takes the user query (prompt) exactly as it is from existing datasets (like ShareGPT or UltraChat).</li>
                            <li><strong>The Model Pool:</strong> It passes that single query to a diverse group of 17 different models—including commercial giants (GPT-4, Claude) and open-source heavyweights (Llama-2, Falcon, Mistral).</li>
                            <li><strong>Random Sampling:</strong> For every user query, it randomly selects 4 models from that pool to generate a response.</li>
                            <li><strong>Principle Variation:</strong> To ensure the responses aren't too similar, it often attaches "principles" (e.g., "be concise" or "prioritize safety") to the system prompt of each model to force diverse styles.</li>
                        </ul>
                        <p>Essentially, it creates a "competition" where the Judge (usually GPT-4) decides which of the 17 possible perspectives handled that specific user query best.</p>
                    </div>
                </details>

                <details class="nested-accordion">
                    <summary>Domain-Specific UltraFeedback Examples</summary>
                    <div class="accordion-content">
                        <ol>
                            <li><strong>Software Engineering (Ground Truth + Pairwise):</strong>
                                <ul>
                                    <li><strong>The Packet:</strong> Prompt (Fibonacci function), Response A (Recursive/Slow), Response B (Iterative/Syntax Error), Ground Truth (Verified Textbook Script).</li>
                                    <li><strong>The Ingestion:</strong> The Judge compares A and B against the Ground Truth. It identifies B's syntax error despite its "advanced" appearance and selects A for the SFT training set.</li>
                                </ul>
                            </li>
                            <li><strong>Medical/BioTech (The Rubric + Pairwise):</strong>
                                <ul>
                                    <li><strong>The Packet:</strong> Prompt (Summarize clinical trial), Response A (Jargon-heavy), Response B (Missing safety warnings), The Rubric (8th-grade level, must include contraindications).</li>
                                    <li><strong>The Ingestion:</strong> The Judge checks both against the Rubric. Both are flagged for failure; the Judge may reject both or pick the "least bad" for further refinement.</li>
                                </ul>
                            </li>
                            <li><strong>Roleplay/Persona (CoT + Pairwise):</strong>
                                <ul>
                                    <li><strong>The Packet:</strong> Prompt (Request for comfort), Response A (Empathetic/Generic), Response B (Stoic/Principled), Instruction (Use Chain of Thought).</li>
                                    <li><strong>Internal Reasoning:</strong> "A is empathetic but lacks the 'Stoic' persona. B uses Stoic principles regarding control. B matches the specific domain requirement." Winner: B.</li>
                                </ul>
                            </li>
                        </ol>
                    </div>
                </details>

                <details class="nested-accordion">
                    <summary>Task-Specific UltraFeedback Examples</summary>
                    <div class="accordion-content">
                        <ol>
                            <li><strong>Mathematical Reasoning (Ground Truth + Pairwise):</strong>
                                <ul>
                                    <li><strong>The Packet:</strong> Prompt (Derivative of $\sin(x^2)$), Response A (Answer only), Response B (Correct steps, sign error), Ground Truth (Step-by-step key).</li>
                                    <li><strong>The Ingestion:</strong> The Judge aligns both against the Ground Truth. It rejects A for failing to show work and flags B for factual error.</li>
                                </ul>
                            </li>
                            <li><strong>Data Extraction (The Rubric + Pairwise):</strong>
                                <ul>
                                    <li><strong>The Packet:</strong> Prompt (Extract contract entities), Response A (Conversational paragraph), Response B (Clean JSON), The Rubric (Valid JSON, specific keys, no filler).</li>
                                    <li><strong>The Ingestion:</strong> The Judge ignores accuracy momentarily to check Rubric constraints. Response A fails; Response B passes all points and is selected.</li>
                                </ul>
                            </li>
                            <li><strong>Creative Writing/Style Transfer (CoT + Pairwise):</strong>
                                <ul>
                                    <li><strong>The Packet:</strong> Prompt (Rewrite manual in '1950s Noir'), Response A (Slang only), Response B (Atmospheric narrative with technical accuracy).</li>
                                    <li><strong>Internal Reasoning:</strong> "A is brief but lacks narrative depth. B maintains the technical requirement (grounded outlet) while committing to the genre's tropes." Winner: B.</li>
                                </ul>
                            </li>
                        </ol>
                    </div>
                </details>

            </div>
        </details>
    </div>
    </details>

    <details class="section">
        <summary>3. Dataset Construction</summary>
        <div class="section-content">
            <p>Packaging the curated data into machine-readable formats for training.</p>
            
            <div class="subsection">
                <span class="subsection-title">Instruction Dataset Formats</span>
                <p>Instruction datasets organize text for AI training.</p>
                <ul>
                    <li><strong>Alpaca:</strong> format is designed for single-turn tasks (one prompt, one reply).</li>
                    <li><strong>ShareGPT or OpenAI:</strong> for multi-turn conversations are superior because they track dialogue history using lists of messages.</li>
                </ul>
            </div>

            <div class="subsection">
                <span class="subsection-title">Chat Templates</span>
                <p>Chat templates are formatting schemas so that the model understands who is speaking (e.g., User vs. Assistant).</p>
                <ul>
                    <li><strong>Foundational Model:</strong> A raw model trained only to predict the next word in a sequence.</li>
                    <li><strong>Instruct Model:</strong> A base model that has been "fine-tuned" to follow instructions. This training process bakes in a specific template. You must reuse that exact template, or the model will lose the context of the conversation.</li>
                </ul>
                <p>Chat templates rigorously structure text into three roles: system, user, and assistant.</p>
            </div>
        </div>
    </details>

    <details class="section">
        <summary>4. Training & Alignment</summary>
        <div class="section-content">
            <p>Execution of the training process and alignment with human preferences.</p>
    
            <details class="nested-accordion">
                <summary>Fine-Tuning Methods (LoRA & QLoRA)</summary>
                <div class="accordion-content">
                    
                    <details class="nested-accordion">
                        <summary>
                            LoRA - Low Rank Adaptation
                            <button class="eye-btn" onclick="event.stopPropagation(); const v = document.querySelector('.retro-viewport'); v.querySelector('iframe').src='SFT/LoRA.html'; v.classList.add('active');">
                                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                                    <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                                    <circle cx="12" cy="12" r="3"></circle>
                                </svg>
                            </button>
                        </summary>
                        <div class="accordion-content">
                            <div class="subsection">
                                <p>Instead of retraining a model’s entire massive web of parameters—which requires immense computational power—LoRA "nudges" the base model's weights.</p>
                                
                                <p><strong>1. Base Model Preparation:</strong> Load your pre-trained model (the "Base Model") in a quantized format (e.g., 4-bit) to save memory. You must "freeze" the model, ensuring no original parameters will be updated during training.</p>
                                
                                <p><strong>2. Configuration:</strong> You must define a <code>LoraConfig</code> object to dictate how the adaptation works:</p>
                                <ul>
                                    <li><strong>r (Rank):</strong> Set the dimension of the low-rank matrices ($A$ and $B$). Start with 8 or 16. Higher ranks allow for more complex learning but increase VRAM usage.</li>
                                    <li><strong>lora_alpha (Alpha):</strong> The scaling factor. A standard heuristic is $\alpha = 2 \times r$.</li>
                                    <li><strong>target_modules:</strong> Specific layers to attach LoRA to.
                                        <details class="nested-accordion">
                                            <summary>Attention Layers: The Relational "Knobs"</summary>
                                            <div class="accordion-content">
                                                <p>In a Transformer, the Attention mechanism determines how tokens interact. Tweaking these layers is about modifying <strong>behavior, focus, and structure</strong>.</p>
                                                
                                                <div class="subsection">
                                                    <span class="subsection-title">Query (q_proj) & Key (k_proj)</span>
                                                    <p>These define the "Search & Match" logic.</p>
                                                    <p><strong>When to Tweak:</strong> Use these when the model struggles with <strong>contextual logic</strong> or <strong>instruction following</strong>. If the model loses the thread in long-form RAG prompts or fails to identify specific entities you've defined, updating $Q$ and $K$ improves its "navigational" accuracy within the text.</p>
                                                </div>
                                    
                                                <div class="subsection">
                                                    <span class="subsection-title">Value (v_proj) & Output (o_proj)</span>
                                                    <p>These carry the "Payload." Once the "Match" is made, the Value layer determines exactly <em>what</em> information is passed forward.</p>
                                                    <p><strong>When to Tweak:</strong> These are the primary targets for <strong>Style, Tone, and Format</strong>. If you want your model to adopt a "Ditherpunk" technical persona or strictly output valid JSON, $V$ is where those stylistic "flavors" are encoded. It changes the <em>result</em> of the attention, not just what the model is looking at.</p>
                                                </div>
                                    
                                                <p><strong>The Selection Rule:</strong> If you want to change <strong>how the model thinks</strong> or <strong>how it speaks</strong>, focus on Attention. It is the most VRAM-efficient way to steer a model's existing personality toward a new task.</p>
                                            </div>
                                        </details>
                                    
                                        <details class="nested-accordion">
                                            <summary>MLP Layers: The Knowledge "Storage"</summary>
                                            <div class="accordion-content">
                                                <p>The Multi-Layer Perceptron (MLP) acts as the model's <strong>internal database</strong>. It processes tokens in isolation to refine their meaning based on learned patterns.</p>
                                                
                                                <div class="subsection">
                                                    <span class="subsection-title">Gate (gate_proj) & Up (up_proj)</span>
                                                    <p>These act as the "Filter & Expand" mechanism (specifically in SwiGLU architectures like Llama). They determine which features of a token are important and project them into a higher-dimensional space for processing.</p>
                                                    <p><strong>When to Tweak:</strong> Tweak these when you are performing <strong>Domain Adaptation</strong>. If you are introducing the model to "Core deep learning methods for CNNs" or specific "Bayesian Modeling" concepts that weren't in the base training, these layers act as the "empty shelves" where new factual associations are stored.</p>
                                                </div>
                                    
                                                <div class="subsection">
                                                    <span class="subsection-title">Down (down_proj)</span>
                                                    <p>This projects the expanded information back down to the model's standard dimension. It acts as a "Summary" step.</p>
                                                    <p><strong>When to Tweak:</strong> This is crucial for <strong>high-density technical learning</strong>. It helps the model "compress" new, complex domain knowledge into its existing architecture without causing "catastrophic forgetting."</p>
                                                </div>
                                    
                                                <p><strong>The Selection Rule:</strong> If you are teaching the model <strong>new facts, specialized jargon, or complex data relationships</strong> (like your work in Distributed Learning), you <em>must</em> include MLP layers. While Attention handles the "vibe," the MLP handles the "substance."</p>
                                            </div>
                                        </details>
                                    </li>
                                </ul>
                                
                                <p><strong>3. Model Injection:</strong> Model Injection involves attaching small, trainable matrices ($A$ and $B$) to the frozen layers of the base model. During the forward pass, data flows through both the frozen base model and the parallel adapters simultaneously to achieve two goals:</p>
    
                                <div class="directory-tree" style="padding-left: 10px;">
                                    <style>
                                        /* Specific styling for the directory tree visualization within this block */
                                        .directory-tree .nested-accordion {
                                            position: relative;
                                            border-left: 2px dashed var(--fg-color); /* The trunk */
                                            margin-left: 10px;
                                            padding-left: 20px;
                                            margin-bottom: 10px;
                                        }
                                        .directory-tree .nested-accordion::before {
                                            content: '';
                                            position: absolute;
                                            top: 15px; /* Aligns branch with the summary text */
                                            left: 0;
                                            width: 15px;
                                            height: 2px;
                                            background-color: var(--fg-color); /* The branch */
                                        }
                                        .directory-tree summary {
                                            cursor: pointer;
                                            transition: all 0.2s ease;
                                            display: inline-block;
                                            width: auto;
                                        }
                                        .directory-tree summary:hover {
                                            background-color: var(--fg-color);
                                            color: var(--bg-color);
                                        }
                                    </style>
                                    
                                    <details class="nested-accordion">
                                        <summary>Establishing the Baseline</summary>
                                        <div class="accordion-content">
                                            <p>The data passes through the Base Model to utilize its massive, pre-trained knowledge bank. This provides the foundational "guess" for the output.</p>
                                        </div>
                                    </details>
    
                                    <details class="nested-accordion">
                                        <summary>Calculating the Nudge</summary>
                                        <div class="accordion-content">
                                            <p>Simultaneously, the data flows through Matrices $A$ and $B$. These matrices learn the delta ($\Delta W$)—a precise mathematical offset. Initially, this path represents zero change, but over time, it learns exactly how much to "tweak" the baseline output to meet the new target.</p>
                                        </div>
                                    </details>
                                </div>
    
                                <p style="margin-top: 10px;">This parallel flow is the key to LoRA's efficiency: by comparing the base model's static prediction with the adapter's variable "tweak," the system can steer the model's output without risking catastrophic forgetting of the original general knowledge.</p>
                                
                                <p><strong>4. Training:</strong> During backpropagation, the optimizer only updates the specific LoRA matrices. This prevents "catastrophic forgetting" of the base model's knowledge.</p>
                                
                                <p><strong>5. Merging & Inference:</strong> The math for the final output is: $W_{final} = W_{base} + (B \times A \times \alpha/r)$. Because LoRA is additive, you nudge the model's general knowledge rather than replacing it.</p>
                            </div>
                        </div>
                    </details>
                    
                    <details class="nested-accordion">
                        <summary>QLoRA - Quantized LoRA</summary>
                        <div class="accordion-content">
                            <div class="subsection">
                                <p>Think of QLoRA as LoRA with a world-class packing strategy. It maintains the same low-rank logic but adds layers of compression to make massive models fit on modest hardware.</p>
                                
                                <p><strong>1. Base Model Preparation (4-bit Quantization):</strong> Loads weights using 4-bit NormalFloat (NF4). This specialized data type ensures minimal information loss while slashing VRAM requirements by up to 75% compared to full-precision tuning.</p>
                                
                                <p><strong>2. Configuration:</strong> Adds two critical features via <code>BitsAndBytesConfig</code>:</p>
                                <ul>
                                    <li><strong>Double Quantization:</strong> Quantizes the quantization constants, saving ~0.37 bits per parameter.</li>
                                    <li><strong>Paged Optimizers:</strong> Acts as a "safety valve," offloading optimizer states to CPU RAM during VRAM spikes to prevent OOM errors.</li>
                                </ul>
                                
                                <p><strong>3. Matrix Injection:</strong> The base model remains in 4-bit storage. During the forward pass, the model performs a "temporary inflation": it dequantizes weights into 16-bit just long enough to perform math with the high-resolution Bfloat adapters.</p>
                                
                                <p><strong>4. Training (The Computational Trade-off):</strong> Only high-precision adapters are updated. Because of the constant inflation/deflation of weights, QLoRA is roughly 30% slower than standard LoRA.</p>
                                
                                <p><strong>5. Merging & Inference:</strong> $W_{final} = Dequantize(W_{4bit}) + (B \times A \times \alpha/r)$. Typically, the base model and adapter are loaded separately at runtime to maintain maximum precision.</p>
                            </div>
                        </div>
                    </details>
    
                </div>
            </details>

            <details class="nested-accordion">
                <summary>Reinforcement Learning from Human Feedback (RLHF)</summary>
                <div class="accordion-content">
                    <p>RLHF is most effective when the "ground truth" is difficult to define mathematically but easy for a human to recognize. The Bradley-Terry model turns a simple "A is better than B" vote into a mathematical probability. If a human prefers response $A$ over $B$, the loss function penalizes the model if its predicted score for $A$ isn't higher than its score for $B$.</p>
                    <ol>
                        <li><strong>The Reward Model (Learning "Taste"):</strong> The Reward Model (RM) is typically a sibling of the candidate model (same architecture) but modified with a scalar regression head. Instead of predicting the next word, it outputs a single number. Using a Bradley-Terry loss, the RM learns to distinguish the features—logic, tone, safety—that humans prefer.</li>
                        <li><strong>Policy Selection (PPO):</strong> Updates $\pi_\theta$ (parameters) via on-policy optimization. Its $KL-penalty$ mechanism enforces a constraint, providing a stable framework for aligning weights with the optimal policy.</li>
                        <li><strong>How the RM Informs the Candidate:</strong> The candidate model generates a response. The RM "grades" it with a score. PPO then calculates the <strong>Advantage</strong>: how much better this response was compared to the model's average.
                            <ul>
                                <li><strong>Positive score:</strong> The model is nudged to produce similar outputs.</li>
                                <li><strong>Negative score:</strong> The model is nudged away.</li>
                            </ul>
                        </li>
                    </ol>
                </div>
            </details>

            <details class="nested-accordion">
                <summary>Preference Alignment (DPO)</summary>
                <div class="accordion-content">
                    <p>Preference alignment addresses the shortcomings of SFT by incorporating direct human or AI feedback into the training process. If SFT is the foundation of competence (getting the answer right), preference data is the layer of alignment (getting the answer right for the specific user, context, or value system).</p>
                    
                    <div class="subsection">
                        <span class="subsection-title">Direct Preference Optimization (DPO)</span>
                        
                        <p>Maximize the <strong>accuracy, diversity, and complexity</strong> of our samples. The algorithm calculates the probability of the model generating the "chosen" response versus the "rejected" response. The goal is to maximize the margin between the two. The model learns not just "what to say," but specifically "what not to say" in the context of what it should say. </p>
                        
                        
                        <p><strong>Data Quantity:</strong> DPO is sample-efficient, meaning it requires significantly less data than SFT to fundamentally change a model’s behavior.</p>
                        <ul>
                            <li><strong>General-Purpose (The Giants):</strong> Industry leaders use millions of pairs (often synthetic) to push the limits of reasoning and global safety.</li>
                            <li><strong>Open-Source Standard:</strong> 10k–100k samples are typically used to boost benchmark scores or "heal" a model’s logic after it has been merged or pruned.</li>
                            <li><strong>Task-Specific (The Sniper):</strong> Narrow objectives—like changing a model's persona or enforcing a specific writing style—can be achieved with as few as 100–10,000 pairs.</li>
                        </ul>
                    </div>
        
                    <div class="subsection">
                        <span class="subsection-title">Generating Preferences</span>
                        <ul>
                            <li><strong>LLM-Human:</strong> AI generates options, humans rank them. This is a high-value hybrid; it is easier for humans to judge quality than to create it from scratch, ensuring efficiency and accuracy.</li>
                            <li><strong>LLM-LLM (Synthetic):</strong> Fully automated. It is the most scalable and cheapest option but requires strict oversight to avoid amplifying model biases.</li>
                        </ul>
                        <p><strong>Model Contrasting:</strong> You prompt two models with one input: a "teacher" (e.g., GPT-4) and a smaller model. The teacher’s output is labeled chosen and the smaller one rejected. This creates a clear signal of high-quality reasoning versus mediocre attempts, teaching the target model to recognize the specific "delta" in quality, logic, and formatting.</p>
                        <p><strong>Human-AI Benchmarking in Practice:</strong> In practice, you take a "gold standard" response written by a human and pair it with a draft from your model. You label the human version as preferred and the AI version as rejected.</p>
                        <ul>
                             <li><strong>Authenticity:</strong> It forces the model to move past generic "AI-speak" and adopt a specific human tone.</li>
                             <li><strong>Edge Cases:</strong> It identifies where models fail at nuanced tasks, like humor or high-level professional jargon.</li>
                             <li><strong>Style Mimicry:</strong> Essential when you need a model to sound like a specific brand or technical expert.</li>
                        </ul>
                    </div>
                </div>
            </details>
        </div>
    </details>

</div>
</div>
</body>
</html>